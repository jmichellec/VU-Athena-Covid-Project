{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ae934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from OpenDutchWordnet import Wn_grid_parser\n",
    "import argparse\n",
    "import re\n",
    "import nltk\n",
    "import xgboost\n",
    "import re\n",
    "import numpy as np\n",
    "import stanza\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import scale\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn import metrics\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import json\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a5f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        print(text)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    no_emoji = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    # Remove urls\n",
    "    no_urls = re.sub(r\"http\\S+\", \"\", no_emoji)\n",
    "    \n",
    "    # Remove punctuation, numbers and symbols\n",
    "    no_punct_symbols_nrs = re.sub(r'[^A-Za-z\\s]+', '', no_urls)\n",
    "    \n",
    "    # Remove trailing white space\n",
    "    no_trailing_ws = \" \".join(no_punct_symbols_nrs.split())\n",
    "    \n",
    "    # Lowercase\n",
    "    text_clean = no_trailing_ws.lower()\n",
    "    return text_clean\n",
    "\n",
    "def lemmatize(nlp, text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized = [word.lemma for sent in doc.sentences for word in sent.words]\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f59561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(nlp, df_train, df_test):\n",
    "    # Clean text\n",
    "    df_train['clean_text'] = df_train['text'].apply(lambda x: clean_text(x))\n",
    "\n",
    "    # Remove empty values\n",
    "    df_train = df_train[df_train['clean_text'] != '']\n",
    "    \n",
    "    # Lemmatize \n",
    "    df_train['lemmatized_clean_text'] = df_train['clean_text'].apply(lambda x: lemmatize(nlp, x))    \n",
    "\n",
    "    df_test['clean_text'] = df_test['message'].apply(lambda x: clean_text(x))\n",
    "    df_test = df_test[df_test['clean_text'] != '']        \n",
    "    df_test['lemmatized_clean_text'] = df_test['clean_text'].apply(lambda x: lemmatize(nlp, x))  \n",
    "    \n",
    "    # Binary labels\n",
    "    df_test['labels'].replace({\"y\": 1, \"n\": 0}, inplace=True)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb987416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypernyms (instance, synset_id, hypers):\n",
    "    synset = instance.synsets_find_synset(synset_id)\n",
    "    if synset:\n",
    "        hypernyms = synset.get_relations(\"has_hyperonym\")\n",
    "        if hypernyms:\n",
    "            for h in hypernyms:\n",
    "                if (h):\n",
    "                    if not h.get_target() in hypers:\n",
    "                        hypers.append(h.get_target())\n",
    "                        get_hypernyms(instance, h.get_target(), hypers)\n",
    "\n",
    "\n",
    "def get_hypernyms_lemmas():\n",
    "    # ['ontmoeten',\n",
    "    #  'voelen',\n",
    "    #  'meemaken',\n",
    "    #  'ondervinden',\n",
    "    #  'ondergaan',\n",
    "    #  'gevoelen',\n",
    "    #  'zich omkleden',\n",
    "    #  'ervaren',\n",
    "    #  'gewaarworden',\n",
    "    #  'kenteren',\n",
    "    #  'doorleven',\n",
    "    #  'veranderen',\n",
    "    #  'keren',\n",
    "    #  'beleven']\n",
    "    instance = Wn_grid_parser(path_wn_grid_lmf='odwn_orbn_gwg-LMF_1.3.xml.gz')\n",
    "    le_el = instance.les_find_le(\"voelen-v-2\")\n",
    "    synset_el = instance.synsets_find_synset(le_el.get_synset_id())\n",
    "    hypers = []\n",
    "    get_hypernyms(instance, synset_el.get_id(), hypers)\n",
    "    new_hypers = []\n",
    "\n",
    "    lemmas = []\n",
    "    for hyper in hypers:\n",
    "        new_hypers.append(hyper)\n",
    "        for le in instance.les_all_les_of_one_synset(hyper):\n",
    "            lemmas.append(le.get_lemma())  \n",
    "\n",
    "    for hyper in new_hypers:\n",
    "        hypers = []\n",
    "        get_hypernyms(instance, hyper, hypers)\n",
    "        new_hypers = []\n",
    "        for hyper in hypers:\n",
    "            new_hypers.append(hyper)\n",
    "            for le in instance.les_all_les_of_one_synset(hyper):\n",
    "                lemmas.append(le.get_lemma())\n",
    "                \n",
    "    return list(set(lemmas+['voelen']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c29084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_match(match, clean_text):\n",
    "    if re.search(match, clean_text):\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "    \n",
    "def lemma_replace(word_list, clean_text, lemmatized_clean_text):\n",
    "    clean_text_tokenized = clean_text.split()\n",
    "    for lemma_word in word_list:\n",
    "        if lemma_word in lemmatized_clean_text:\n",
    "            for i, word in enumerate(lemmatized_clean_text.split()):\n",
    "                if word == lemma_word:\n",
    "                    clean_text_tokenized[i] = clean_text_tokenized[i].replace(clean_text_tokenized[i], lemma_word)\n",
    "    clean_text = \" \".join(clean_text_tokenized)\n",
    "    return clean_text\n",
    "\n",
    "def heuristics_labelling(df_train, df_test, WN_synsets, filters, remove):\n",
    "    \n",
    "    df_train['clean_text_lemma'] = df_train['clean_text']\n",
    "    df_test['clean_text_lemma'] = df_test['clean_text']\n",
    "    \n",
    "    matches = []\n",
    "    if 0 in filters:\n",
    "        matches.append(\"((heb|heeft|hebben) [a-z]* (gehad))\")\n",
    "    if 1 in filters:\n",
    "        direct_relation = 'vader|moeder|ouder|schoonvader|schoonmoeder|kind|zoon|dochter|man|vrouw|broer|zus|neef|nicht|tante|oom'\n",
    "        df_train['clean_text_lemma'] = df_train[['clean_text', 'lemmatized_clean_text']].apply(lambda x: lemma_replace(direct_relation.split('|'), x.clean_text, x.lemmatized_clean_text), axis=1)\n",
    "        df_test['clean_text_lemma'] = df_test[['clean_text', 'lemmatized_clean_text']].apply(lambda x: lemma_replace(direct_relation.split('|'), x.clean_text, x.lemmatized_clean_text), axis=1)\n",
    "        \n",
    "        matches.append(\"((mijn|mn|me|m n|mij|men) \" + '(' + direct_relation + '))') \n",
    "                       \n",
    "    if 2 in filters:                       \n",
    "        df_train['clean_text_lemma'] = df_train[['clean_text', 'lemmatized_clean_text']].apply(lambda x: lemma_replace(WN_synsets, x.clean_text, x.lemmatized_clean_text), axis=1)\n",
    "        df_test['clean_text_lemma'] = df_test[['clean_text', 'lemmatized_clean_text']].apply(lambda x: lemma_replace(WN_synsets, x.clean_text, x.lemmatized_clean_text), axis=1)\n",
    "                \n",
    "        matches.append('('+'|'.join(WN_synsets)+')')\n",
    "\n",
    "    match = '|'.join(matches)\n",
    "    df_train['labels'] = df_train['clean_text_lemma'].apply(lambda x: check_match(match, x))\n",
    "    df_test['predicted'] = df_test['clean_text_lemma'].apply(lambda x: check_match(match, x))\n",
    "      \n",
    "    if remove == True:\n",
    "        df_train['clean_text_removals'] = df_train['clean_text_lemma'].apply(lambda x: re.sub(match, '', x))\n",
    "        df_test['clean_text_removals'] = df_test['clean_text_lemma'].apply(lambda x: re.sub(match, '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd049f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(df_train, df_train_labels):\n",
    "    over= RandomOverSampler(sampling_strategy=1, random_state=42)\n",
    "    df_train_sampled, df_train_sampled_labels = over.fit_resample(df_train, df_train_labels)\n",
    "    return df_train_sampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26555487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(df_train, df_test, vectorizer, remove):\n",
    "    vect = vectorizer\n",
    "    y_train = df_train['labels']\n",
    "    y_test = df_test['labels']\n",
    "    if remove == True:\n",
    "        corpus = df_train['clean_text_removals'].tolist()\n",
    "        X_train = vect.fit_transform(corpus)\n",
    "        X_test = vect.transform(df_test['clean_text_removals'])\n",
    "    else:\n",
    "        corpus = df_train['clean_text'].tolist()\n",
    "        X_train = vect.fit_transform(corpus)\n",
    "        X_test = vect.transform(df_test['clean_text'])\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_unlabelled(df_train, df_test, vectorizer, remove):\n",
    "    vect = vectorizer\n",
    "    y_train = df_train['labels']\n",
    "    if remove == True:\n",
    "        corpus = df_train['clean_text_removals'].tolist()\n",
    "        X_train = vect.fit_transform(corpus)\n",
    "        X_test = vect.transform(df_test['clean_text_removals'])\n",
    "    else:\n",
    "        corpus = df_train['clean_text'].tolist()\n",
    "        X_train = vect.fit_transform(corpus)\n",
    "        X_test = vect.transform(df_test['clean_text'])\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb83e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cm(true_labels, predicted_labels):\n",
    "    cm = metrics.confusion_matrix(true_labels, predicted_labels)\n",
    "        \n",
    "    fig, ax = plot_confusion_matrix(conf_mat=cm,\n",
    "                                    colorbar=False,\n",
    "                                    show_absolute=False,\n",
    "                                    show_normed=True,\n",
    "                                    class_names=['non-exp','exp'])\n",
    "    fig.set_size_inches(10, 10.5)\n",
    "\n",
    "    \n",
    "def class_feature_importance(X, Y, feature_importances, vect):\n",
    "    N, M = X.shape\n",
    "    X = scale(X, with_mean=False)\n",
    "\n",
    "    out = {}\n",
    "    for c in set(Y):\n",
    "        out[c] = dict(\n",
    "            zip(vect.get_feature_names(), np.mean(X[Y==c, :], axis=0)*feature_importances)\n",
    "        )\n",
    "\n",
    "    return out    \n",
    "\n",
    "def classification_experiments(X_train, y_train, X_test, y_test):\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"Logistic Regression\")\n",
    "    \n",
    "    clf = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"LR: ROC-AUC:\", roc_auc_score(y_test, y_pred))\n",
    "#     create_cm(y_test, y_pred)\n",
    "    \n",
    "    print(\"--------------------------------\")\n",
    "    print(\"XGBoost Random Forest\")\n",
    "    \n",
    "    xgbc = XGBClassifier(objective=\"binary:logistic\", random_state=42, eval_metric='logloss')\n",
    "    xgb = xgbc.fit(X_train, y_train)\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"XGB: ROC-AUC:\", roc_auc_score(y_test, y_pred))\n",
    "#     create_cm(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4759496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_data_train_test_split(full_df, sub_df, test_df):\n",
    "    test_ids = test_df['object_id'].tolist()\n",
    "    sub_ids = sub_df['object_id'].tolist()\n",
    "    full_df = full_df[~full_df.object_id.isin(test_ids)]\n",
    "    full_df = full_df[~full_df.object_id.isin(sub_ids)]\n",
    "    \n",
    "    # full_df_test is for prediction\n",
    "    full_df_train_no_sentiment, full_df_test = train_test_split(full_df, test_size=0.42, random_state=42)\n",
    "    full_df_train = pd.concat([full_df_train_no_sentiment, sub_df]) #sub_df  is around 2 percent\n",
    "    return full_df_train, full_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e807dfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predicted(unlabelled_df, unlabelled_X_test, best_model, name):\n",
    "    predictions = best_model.predict_proba(unlabelled_X_test)\n",
    "    unlabelled_df['best_model_pred'] = predictions\n",
    "    unlabelled_df[['text', 'best_model_pred']].to_csv(name+'.tsv', delimiter='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68553b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lemmatized_files():\n",
    "    df_train = pd.read_csv('fb_preprocessed_FB_NOS_NU_Telegraaf_NRC_all_endFeb.csv', sep='\\t')\n",
    "    df_test = pd.read_csv('experience_test/Fb_random_sample_500_annotated_discussed.tsv', sep='\\t')\n",
    "    sub_df = pd.read_csv('high_sent_subjFB_NOS_NU_Telegraaf_NRC_all_endFeb.csv', sep='\\t')\n",
    "    \n",
    "    df_train = df_train[~df_train['text'].isna()]\n",
    "    df_test = df_test[~df_test['message'].isna()]\n",
    "    sub_df = sub_df[~sub_df['text'].isna()]\n",
    "    \n",
    "    nlp = stanza.Pipeline(lang='nl', processors='tokenize,pos,lemma')\n",
    "    df_train_sent, df_test_sent = process_data(nlp, sub_df, df_test)\n",
    "    print(\"Finished sentiment\")\n",
    "    df_train, df_test = process_data(nlp, df_train, df_test)\n",
    "    print(\"Finished train and test\")\n",
    " \n",
    "    df_test_sent.to_csv('lemmatized_test_high_sent_subjFB_NOS_NU_Telegraaf_NRC_all_endFeb.tsv', sep='\\t')\n",
    "    df_train_sent.to_csv('lemmatized_train_high_sent_subjFB_NOS_NU_Telegraaf_NRC_all_endFeb.tsv', sep='\\t')\n",
    "\n",
    "    df_train.to_csv('lemmatized_train_fb_preprocessed_FB_NOS_NU_Telegraaf_NRC_all_endFeb.tsv', sep='\\t') # no test \n",
    "    df_test.to_csv('lemmatized_test_fb_preprocessed_FB_NOS_NU_Telegraaf_NRC_all_endFeb.tsv', sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23fff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_models():\n",
    "    # comment this when not using unlabelled    \n",
    "#     df_train = pd.read_csv('lemmatized_train_fb_preprocessed_FB_NOS_NU_Telegraaf_NRC_all_endFeb.tsv', sep='\\t')\n",
    "#     sub_df = pd.read_csv('lemmatized_train_high_sent_subjFB_NOS_NU_Telegraaf_NRC_all_endFeb.tsv', sep='\\t')\n",
    "#     df_train, df_unlabelled = full_data_train_test_split(df_train, sub_df, df_test)\n",
    "#     df_train.to_csv('lemmatized_train_no_unlabelled_fb_preprocessed_FB_NOS_NU_Telegraaf_NRC_all_endFeb.tsv', sep='\\t') \n",
    "#     df_unlabelled.to_csv('lemmatized_unlabelled_fb_preprocessed_FB_NOS_NU_Telegraaf_NRC_all_endFeb.tsv', sep='\\t')\n",
    "\n",
    "    df_train = pd.read_csv('lemmatized_train_no_unlabelled_fb_preprocessed_FB_NOS_NU_Telegraaf_NRC_all_endFeb.tsv', sep='\\t')\n",
    "    df_test = pd.read_csv('lemmatized_test_fb_preprocessed_FB_NOS_NU_Telegraaf_NRC_all_endFeb.tsv', sep='\\t')\n",
    "\n",
    "    WN_synsets = get_hypernyms_lemmas()\n",
    "    \n",
    "    vectorizers = [TfidfVectorizer(), CountVectorizer(binary=True)]\n",
    "    removes = [False, True]\n",
    "    filters = [[0], [1], [2], [0, 1], [1, 2], [0, 2], [0, 1, 2]]\n",
    "    for vect in vectorizers:\n",
    "        print(vect)\n",
    "        print('-----------------')\n",
    "        for remove in removes:\n",
    "            print(remove)\n",
    "            print('-----------------')\n",
    "            for filter_ in filters:\n",
    "                print(filter_)\n",
    "                print('-------------------')\n",
    "                heuristics_labelling(df_train, df_test, WN_synsets, filter_, remove)\n",
    "                print('DATA STATS: ', df_train['labels'].value_counts())\n",
    "\n",
    "                df_train_sampled = resample_data(df_train, df_train['labels'])\n",
    "                X_train, y_train, X_test, y_test = create_train_test(df_train_sampled, df_test, vect, remove)\n",
    "                print('-------------------')\n",
    "                print(\"BASELINE\")\n",
    "                print(classification_report(df_test['labels'], df_test['predicted']))\n",
    "                classification_experiments(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70719b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_labelling(df_train, df_test, df_unlabelled_test, WN_synsets):\n",
    "    # Best XGB \n",
    "    heuristics_labelling(df_train, df_unlabelled_test, WN_synsets, [0,1,2], False)\n",
    "    df_train_sampled = resample_data(df_train, df_train['labels'])\n",
    "    bin_vect = CountVectorizer(binary=True)\n",
    "    X_train, y_train, X_test, y_test = create_train_test(df_train_sampled, df_test, bin_vect, False)\n",
    "\n",
    "    _, _, unlabelled_X_test = create_train_test_unlabelled(df_train_sampled, df_unlabelled_test, bin_vect, False)\n",
    "    \n",
    "    predictions = best_xgb.predict_proba(unlabelled_X_test)[:, 1]\n",
    "\n",
    "    df_unlabelled_test['best_model_pred'] = predictions\n",
    "    df_unlabelled_test[['text', 'best_model_pred']].to_csv('unlabelled_predictions_by_bestmodel.tsv', sep='\\t', index=False)\n",
    "\n",
    "def best_xgb_results(df_train, df_test, WN_synsets):\n",
    "    heuristics_labelling(df_train, df_test, WN_synsets, [0,1,2], False)\n",
    "    df_train_sampled = resample_data(df_train, df_train['labels'])\n",
    "    bin_vect = CountVectorizer(binary=True)\n",
    "    X_train, y_train, X_test, y_test = create_train_test(df_train_sampled, df_test, bin_vect, False)\n",
    "    best_xgb = XGBClassifier(objective=\"binary:logistic\", random_state=42, eval_metric='logloss').fit(X_train, y_train)  \n",
    "    y_pred = best_xgb.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    importance = best_xgb.feature_importances_\n",
    "\n",
    "    result = class_feature_importance(X_test.toarray(), y_pred, importance, bin_vect)\n",
    "\n",
    "    d = result.get(1)\n",
    "\n",
    "    sorted_d = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(sorted_d[:20])\n",
    "    \n",
    "    return best_xgb, y_pred, y_test\n",
    "    \n",
    "def best_lr_results(df_train, df_test, WN_synsets):\n",
    "    heuristics_labelling(df_train, df_test, WN_synsets, [0,1], True)\n",
    "    df_train_sampled = resample_data(df_train, df_train['labels'])\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train, y_train, X_test, y_test = create_train_test(df_train_sampled, df_test, tfidf, True)\n",
    "    clf = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Logistic Regression\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    importance = clf.coef_[0]\n",
    "\n",
    "    result = class_feature_importance(X_test.toarray(), y_pred, importance, tfidf)\n",
    "\n",
    "    d = result.get(1)\n",
    "\n",
    "    sorted_d = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(sorted_d[:20])\n",
    "    \n",
    "    return clf, y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11098803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_dfs():\n",
    "    bm_df = pd.read_csv('predicted_data/unlabelled_predictions_by_xgb-binary-keepfeat.tsv', sep='\\t', header=None)\n",
    "#     bm_df[:250].to_csv('predicted_data/top-250-unlabelled_predictions_by_xgb-binary-keepfeat.tsv', sep='\\t', header=False)\n",
    "\n",
    "    bm_df_unlabelled = bm_df.fillna('Unlabelled')\n",
    "    labelled = bm_df_unlabelled[bm_df_unlabelled[3] != 'Unlabelled']\n",
    "    labelled[[0, 1, 3]].to_csv('predicted_data/workshop_labelled_predictions_by_xgb-binary-keepfeat.csv', sep='\\t', header=False)\n",
    "\n",
    "    bm_df_unlabelled = bm_df[~bm_df[1].isin(labelled.index)]\n",
    "    above_unlabelled_09 = bm_df_unlabelled[bm_df_unlabelled[1] >= 0.9]\n",
    "    above_unlabelled_09_sample = above_unlabelled_09.sample(n=250, random_state=50)\n",
    "    above_unlabelled_09_sample[[0]].to_csv('predicted_data/sample_unlabelledpredictions_over0-9_by_xgb-binary-keepfeat.csv', sep='\\t', header=False, index=False)\n",
    "    \n",
    "    below_unlabelled_09 = bm_df_unlabelled[bm_df_unlabelled[1] < 0.9]\n",
    "    below_unlabelled_09 = below_unlabelled_09[below_unlabelled_09[1] >= 0.5]\n",
    "    below_unlabelled_09_sample = below_unlabelled_09.sample(n=250, random_state=50)\n",
    "    below_unlabelled_09_sample[[0]].to_csv('predicted_data/sample_unlabelledpredictions_below0-9_by_xgb-binary-keepfeat.csv', sep='\\t', header=False, index=False)\n",
    "\n",
    "    \n",
    "#     sns.histplot(below_250_unlabelled[1], stat=\"probability\", bins=10, kde=True)\n",
    "#     below_250_unlabelled['bin'] = pd.cut(below_250[1], 10)\n",
    "#     print(below_250_unlabelled.bin.value_counts())\n",
    "\n",
    "#     sample_df = below_250_unlabelled.groupby('bin').sample(n=100, random_state=1)\n",
    "#     sample_df[[0, 1, 3, 'bin']].to_csv('predicted_data/sample_unlabelled_predictions_by_xgb-binary-keepfeat.tsv', sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485bd35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_preds_index(y_test, y_pred):\n",
    "    return [1 if i == j else 0 for i, j in zip(y_test, y_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f6125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df_train = pd.read_csv('lemmatized_train_no_unlabelled_fb_preprocessed_FB_NOS_NU_Telegraaf_NRC_all_endFeb.tsv', sep='\\t')\n",
    "    df_test = pd.read_csv('lemmatized_test_fb_preprocessed_FB_NOS_NU_Telegraaf_NRC_all_endFeb.tsv', sep='\\t')\n",
    "    df_unlabelled_test = pd.read_csv('lemmatized_unlabelled_fb_preprocessed_FB_NOS_NU_Telegraaf_NRC_all_endFeb.tsv', sep='\\t')\n",
    "    WN_synsets = get_hypernyms_lemmas()\n",
    "    \n",
    "#     create_lemmatized_files()\n",
    "    results_models()\n",
    "#     prediction_labelling(df_train, df_test, df_unlabelled_test, WN_synsets)\n",
    "\n",
    "    print(\"LR\")\n",
    "    lr, y_pred_lr, y_test = best_lr_results(df_train, df_test, WN_synsets)\n",
    "    lr_correct = correct_preds_index(y_test, y_pred_lr)\n",
    "    \n",
    "    print(\"XGB\")\n",
    "    xgb, y_pred_xgb, y_test = best_xgb_results(df_train, df_test, WN_synsets)\n",
    "    xgb_correct = correct_preds_index(y_test, y_pred_xgb)\n",
    "#     create_sample_dfs()\n",
    "\n",
    "    print(\"correct matrix\")\n",
    "    print(confusion_matrix(lr_correct, xgb_correct))\n",
    "    \n",
    "    print(\"prediction matrix\")\n",
    "    print(confusion_matrix(y_pred_lr, y_pred_xgb))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3944f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
