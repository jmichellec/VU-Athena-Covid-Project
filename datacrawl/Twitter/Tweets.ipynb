{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "burning-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adapted-notice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The API-Key and the API-secret were displayed to you after you registered\n",
    "API_KEY = 'EhenNZwate84ihy4D3AUtGQB8'\n",
    "API_SECRET = 'ly0mjcqFj1ra1onG0BCAbDGvMCiERonvVuYXexzBkpjLIBS59W'\n",
    "\n",
    "# The Access token and the Access secret were displayed when you clicked on \"generate\"\n",
    "ACCESS_TOKEN = '378072938-O3yndhLllyWKVfLfXNzloo1PuFIdJapAJQg8sWUY'\n",
    "ACCESS_SECRET = 'ivrsSXGFYhKfl4w5qNXd9rMUZ7Zj0cIFl9Meqnp5k3e9P'\n",
    "\n",
    "# Setup tweepy to authenticate with Twitter credentials:\n",
    "auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "# Create the api to connect to twitter with your credentials\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "based-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tweets that have certain keywords\n",
    "\n",
    "def get_relevant_tweets(keywords, user_ids, tsv_filename, filters):\n",
    "    date = datetime.datetime.now()\n",
    "    \n",
    "    # Optional: we can define a filter, for example, to ignore retweets\n",
    "    filter = '-filter:retweets'\n",
    "    \n",
    "    # Write them to a file\n",
    "    tsv_file = tsv_filename + date.strftime(\"%d-%b-%Y\") + '.tsv'\n",
    "\n",
    "    with open(tsv_file, 'w', encoding='utf-8') as outfile:\n",
    "        tsv_header = 'Type of Tweet\\tCreated at\\tUser\\tNum_Favorites\\tNum_Retweets\\tTweet\\n'\n",
    "        outfile.write(tsv_header)    \n",
    "\n",
    "        for user_id in user_ids:\n",
    "            print(user_id)\n",
    "            # Query keywords from specific user\n",
    "            if filters == 'y':\n",
    "                query = keywords + ' ' + 'from:' + user_id + ' ' + filter\n",
    "            else: \n",
    "                query = keywords + ' ' + 'from:' + user_id\n",
    "\n",
    "            # Optional: Determine a date range to limit the results \n",
    "            # start_date = '2020-03-14'\n",
    "            # end_date = '2021-02-19'\n",
    "\n",
    "            # Optional: Limit the number of tweets  \n",
    "            # nr_tweets = 100\n",
    "\n",
    "            # Request all tweets with premium key\n",
    "            #api.search_full_archive\n",
    "            \n",
    "            # Currently it goes only 7 days in advance or something\n",
    "            tweet_iterator = tweepy.Cursor(api.search, q=query, tweet_mode='extended').items()\n",
    "\n",
    "            tweets = list(tweet_iterator)\n",
    "\n",
    "            for i, tweet in enumerate(tweets): \n",
    "\n",
    "                # Get tweet of opinion leader\n",
    "                # attributes: type of tweet, created_at, username, favorite count, retweet count, text.\n",
    "                text = tweet.full_text.replace('\\n', ' ')\n",
    "                tweet_row = 'Tweet_' + str(i) + '\\t' + str(tweet.created_at) + '\\t' + str(tweet.user.screen_name) + '\\t' + str(tweet.favorite_count) + '\\t' + str(tweet.retweet_count) + '\\t' + text + '\\n'\n",
    "                outfile.write(tweet_row)    \n",
    "\n",
    "                # Get replies on that specific tweet using tweet_id\n",
    "                q_reply = 'to:' + user_id\n",
    "                reply_tweets = tweepy.Cursor(api.search, q=q_reply, since_id=id, max_id=id, tweet_mode='extended').items()\n",
    "                for reply in reply_tweets:\n",
    "                    if hasattr(reply, 'in_reply_to_status_id_str'):\n",
    "                        if (reply.in_reply_to_status_id_str==tweet.id_str):\n",
    "                            reply_text = reply.full_text.replace('\\n', ' ')\n",
    "                            reply_row = 'Reply_' + str(i) + '\\t' + str(reply.created_at) + '\\t' + str(reply.user.screen_name) + '\\t' + str(reply.favorite_count) + '\\t' + str(reply.retweet_count) + '\\t' + reply_text + '\\n'                        \n",
    "                            outfile.write(reply_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "miniature-checkout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_Bruijning\n",
      "MarcBonten\n",
      "MarcelFVerweij\n",
      "MarionKoopmans\n",
      "mkeulemans\n",
      "amcvanrossum\n",
      "JochenCals\n",
      "Eefje_de_Bont\n",
      "IGJnl\n"
     ]
    }
   ],
   "source": [
    "keywords = '((covid OR corona OR coronavirus) AND (vaccin OR vaccinatie OR vaccins OR vaccinaties OR prik OR vaccineren OR prikken)) OR (coronavaccin OR coronavirusvaccin OR covidvaccin OR coronavaccins OR covidvaccins OR coronavaccinaties OR covidvaccinaties OR coronaprik)'\n",
    "# keywords_extra = '((covid OR corona) AND (vaccin OR vaccinatie OR vaccins OR vaccinaties OR prik OR vaccineren OR prikken)) OR (coronavaccin OR covidvaccin OR coronavaccins OR covidvaccins OR coronavaccinaties OR covidvaccinaties OR coronaprik OR vaccineren OR vaccinaties OR prik OR prikken OR vaccinatie OR vaccin OR vaccins)'\n",
    "\n",
    "opinion_leaders = ['P_Bruijning', 'MarcBonten', 'MarcelFVerweij', 'MarionKoopmans',\n",
    "              'mkeulemans', 'amcvanrossum', 'JochenCals', 'Eefje_de_Bont','IGJnl']\n",
    "tsv_filename_leaders = 'opinionleaders_tweets_'\n",
    "\n",
    "get_relevant_tweets(keywords, opinion_leaders, tsv_filename_leaders, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "important-retreat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Herstel_NL\n",
      "CoronaOnderzoek\n",
      "OudersDe\n",
      "BuuropReis\n",
      "BertHuisjes\n",
      "WNLOpiniemakers\n",
      "WNLVandaag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArmandGirbes\n",
      "ClaimedIn\n",
      "_GezondVerstand\n",
      "irene_kamp\n",
      "aukew\n",
      "JKNL\n",
      "tussenmeer\n",
      "leonardwitkamp\n",
      "DaanDeWit\n",
      "Ronald_Roothans\n",
      "huisartsleiden\n",
      "hapelensrob\n",
      "ZelfzorgCovid19\n",
      "MdeGruyter\n",
      "Sabrina_Nachter\n",
      "Gezondheidszorg\n",
      "DStuijver\n",
      "medischcontact\n",
      "BartVanHelden1\n",
      "hetAVL\n",
      "Infocadl2015\n",
      "VoedingLeeft\n",
      "GvRookvrij\n",
      "RutgervdNoort\n",
      "arts_leefstijl\n",
      "J_van_Roosmalen\n",
      "BorgerPieter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hugovdwedden\n",
      "artsJannes\n",
      "Wdekanter\n",
      "corenona20\n",
      "Alicia1984N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dutchanddonts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MauricevdBosch\n",
      "BertMesselink\n",
      "BetermetBUi\n",
      "nvzziekenhuizen\n",
      "KNMP\n",
      "KNMG\n",
      "Peter_Voshol\n",
      "m2_nl\n",
      "huisartslieneke\n",
      "GioMeijer\n",
      "Fitdieet\n",
      "Coach_Mindtrain\n",
      "RF_HFC\n",
      "koosdirkse\n",
      "DokterJanneke\n",
      "EsthervanFenema\n"
     ]
    }
   ],
   "source": [
    "# ArtsenC following\n",
    "keywords = '((covid OR corona OR coronavirus) AND (vaccin OR vaccinatie OR vaccins OR vaccinaties OR prik OR vaccineren OR prikken)) OR (coronavaccin OR coronavirusvaccin OR covidvaccin OR coronavaccins OR covidvaccins OR coronavaccinaties OR covidvaccinaties OR coronaprik)'\n",
    "# keywords_extra = '((covid OR corona) AND (vaccin OR vaccinatie OR vaccins OR vaccinaties OR prik OR vaccineren OR prikken)) OR (coronavaccin OR covidvaccin OR coronavaccins OR covidvaccins OR coronavaccinaties OR covidvaccinaties OR coronaprik OR vaccineren OR vaccinaties OR prik OR prikken OR vaccinatie OR vaccin OR vaccins)'\n",
    "\n",
    "df = pd.read_csv('list of interesting tweeters COVID.csv', sep=';')\n",
    "df = df[df['Important'].notna()]\n",
    "interesting_tweeters = df['Following'].tolist()\n",
    "\n",
    "tsv_interesting_tweeters = 'artsenC_following_covidvaccin_tweets_'\n",
    "get_relevant_tweets(keywords, interesting_tweeters, tsv_interesting_tweeters, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caroline-ethics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daargaanweweetj\n",
      "Bartissimus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nimnyana\n",
      "huisdoktertim\n",
      "dwingel58\n",
      "doktertweets\n",
      "maasvdn\n",
      "ForensischArts\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ikvaccineer_medical.tsv', delimiter='\\t')\n",
    "ikvaccineer_medicals = df['screen_name'].tolist()\n",
    "tsv_interesting_tweeters = 'medicals_covidvaccin_tweets_retweets_'\n",
    "get_relevant_tweets(keywords, ikvaccineer_medicals, tsv_interesting_tweeters, 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "meaning-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try filter ppl who have health-related job in their bio: “arts”, “verpleegkundige” + #ikvaccineer or #ikvaccineerniet\n",
    "# # Download all tweets with  (covid and vaccin) + comments on those\n",
    "# # NO RETWEETS\n",
    "\n",
    "# Get ppl with #ikvaccineer or #ikvaccineerniet\n",
    "def ik_vaccineer_or_not_people(q, filename, num):\n",
    "    language = 'nl'\n",
    "    query = q\n",
    "    users = list(tweepy.Cursor(api.search_users, q=query, iso_language_code=language, tweet_mode='extended', lang = 'nl').items(num))\n",
    "    with open(filename, 'a', encoding='utf-8') as outfile:\n",
    "#         tsv_header = 'screen_name\\tname\\tbio\\n'\n",
    "#         outfile.write(tsv_header)\n",
    "        \n",
    "#     with open(filename, 'a', encoding='utf-8') as outfile:\n",
    "        for user in users:\n",
    "            print(user.screen_name)\n",
    "            row = user.screen_name + '\\t' + user.name + '\\t' + user.description + '\\n'\n",
    "            outfile.write(row)\n",
    "            \n",
    "# ik_vaccineer_or_not_people('#ikvaccineer', 'ikvaccineer_people.tsv', 1000)\n",
    "# ik_vaccineer_or_not_people('#ikvaccineerniet', 'ikvaccineerniet_people.tsv', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pressed-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ik_vaccineer_or_not_medical(ikvaccfile, keywords, filename):\n",
    "    ikvaccdf = pd.read_csv(ikvaccfile, delimiter='\\t')\n",
    "    ikvacc_med = ikvaccdf[ikvaccdf['name'].str.contains(keywords) | ikvaccdf['bio'].str.contains(keywords)]\n",
    "    ikvacc_med = ikvacc_med.drop_duplicates()\n",
    "    \n",
    "    with open(filename, 'a', encoding='utf-8') as outfile:\n",
    "        # tsv_header = 'screen_name\\tname\\tbio\\n'\n",
    "        # outfile.write(tsv_header)\n",
    "        for index, row in ikvacc_med.iterrows():    \n",
    "            rows = row[0] + '\\t' + row[1] + '\\t' + row[2] + '\\n'\n",
    "            outfile.write(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "expressed-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords = \"arts|dokter|verpleeg|medisch|immunoloog|vaccinoloog|epidemioloog|geneeskundige|geriaters\"\n",
    "\n",
    "# ik_vaccineer_or_not_medical('ikvaccineer_people.tsv', keywords, 'ikvaccineer_medical.tsv')\n",
    "# ik_vaccineer_or_not_medical('ikvaccineerniet_people.tsv', keywords, 'ikvaccineerniet_medical.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "particular-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge files\n",
    "# def merge_files(merge_file_list, outname):\n",
    "#     content = []\n",
    "#     for file in merge_file_list:\n",
    "#         with open(file, \"r\", encoding='utf-8') as f:\n",
    "#             lines = f.read().splitlines()\n",
    "#             if len(lines) > 1:\n",
    "#                 content+=lines\n",
    "\n",
    "#     df = pd.DataFrame([sub.split('\\t') for sub in content])\n",
    "#     df.columns = df.iloc[0]\n",
    "#     df = df[1:]\n",
    "#     df.to_csv(outname, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "driven-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_follow_file(acc_name, tsv_filename):\n",
    "    date = datetime.datetime.now()\n",
    "    tsv_file = tsv_filename +  date.strftime(\"%d-%b-%Y\") + '.csv'\n",
    "    with open(tsv_file, 'w', encoding='utf-8') as outfile:\n",
    "        tsv_header = 'Following\\n'\n",
    "        outfile.write(tsv_header)\n",
    "\n",
    "        for following in tweepy.Cursor(api.friends, screen_name=acc_name).items():\n",
    "            outfile.write(following.screen_name +'\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "innocent-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_follow_file('ArtsenC', 'ArtsenC_following_')\n",
    "# get_follow_file('RIVM', 'RIVM_following_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accepting-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting the retweeters \n",
    "# retweets_list = api.retweets(ID) \n",
    "  \n",
    "# # printing the screen names of the retweeters \n",
    "# for retweet in retweets_list: \n",
    "#     print(retweet.user.screen_name) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
